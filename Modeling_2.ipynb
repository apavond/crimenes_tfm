{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de crímenes\n",
    "### Trabajo Fin de Máster para el Máster Universitario en Ciencia de Datos\n",
    "### Universitat Oberta de Catalunya\n",
    "### Realizado por Álvaro Pavón Díaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Modelado y evaluación de los datos\n",
    "Durante este Jupyter Notebook nos dedicaremos a realizar el entrenamiento de los conjunto de datos sobre diferentes métodos.\n",
    "\n",
    "Para ello lo primero se va a proceder a importar las diferentes clases que se necesitarán a lo largo de este notebook y la importación de los archivos que se va a utilizar. Además de mostrar que los proceso realizados a través de TensorFlow van a ser acelerados mediante GPU (GeForce RTX 2070 SUPER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1794315526548503137\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6586313605\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12686134853631233297\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5\"\n",
      "]\n",
      "<module 'tensorflow_core._api.v2.version' from 'C:\\\\Users\\\\darkc\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages\\\\tensorflow_core\\\\_api\\\\v2\\\\version\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_CODE_GROUP</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>SHOOTING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>STREET</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>IS_NIGHT</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disorderly Conduct</td>\n",
       "      <td>E18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>20</td>\n",
       "      <td>ARLINGTON ST</td>\n",
       "      <td>42.262608</td>\n",
       "      <td>-71.121186</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Property Lost</td>\n",
       "      <td>D14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>20</td>\n",
       "      <td>ALLSTON ST</td>\n",
       "      <td>42.352111</td>\n",
       "      <td>-71.135311</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>19</td>\n",
       "      <td>DEVON ST</td>\n",
       "      <td>42.308126</td>\n",
       "      <td>-71.076930</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>A1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>20</td>\n",
       "      <td>CAMBRIDGE ST</td>\n",
       "      <td>42.359454</td>\n",
       "      <td>-71.059648</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aircraft</td>\n",
       "      <td>A7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>20</td>\n",
       "      <td>PRESCOTT ST</td>\n",
       "      <td>42.375258</td>\n",
       "      <td>-71.024663</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OFFENSE_CODE_GROUP DISTRICT  SHOOTING  YEAR  MONTH DAY_OF_WEEK  HOUR  \\\n",
       "0  Disorderly Conduct      E18       0.0  2018     10   Wednesday    20   \n",
       "1       Property Lost      D14       0.0  2018      8    Thursday    20   \n",
       "2               Other       B2       0.0  2018     10   Wednesday    19   \n",
       "3  Aggravated Assault       A1       0.0  2018     10   Wednesday    20   \n",
       "4            Aircraft       A7       0.0  2018     10   Wednesday    20   \n",
       "\n",
       "         STREET        Lat       Long  IS_NIGHT  DAY_OF_MONTH  \n",
       "0  ARLINGTON ST  42.262608 -71.121186         1             3  \n",
       "1    ALLSTON ST  42.352111 -71.135311         1            30  \n",
       "2      DEVON ST  42.308126 -71.076930         1             3  \n",
       "3  CAMBRIDGE ST  42.359454 -71.059648         1             3  \n",
       "4   PRESCOTT ST  42.375258 -71.024663         1             3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes = pd.read_csv ('crimes_clean.csv', sep='\"\"', delimiter=',', engine='python')\n",
    "crimes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_CODE_GROUP</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>SHOOTING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>STREET</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>IS_NIGHT</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>TIME_X</th>\n",
       "      <th>TIME_Y</th>\n",
       "      <th>Lat_M</th>\n",
       "      <th>Long_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desorden</td>\n",
       "      <td>E18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>20</td>\n",
       "      <td>ARLINGTON ST</td>\n",
       "      <td>42.262608</td>\n",
       "      <td>-71.121186</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.518198</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.185665</td>\n",
       "      <td>0.267386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Otros</td>\n",
       "      <td>D14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>20</td>\n",
       "      <td>ALLSTON ST</td>\n",
       "      <td>42.352111</td>\n",
       "      <td>-71.135311</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.239106</td>\n",
       "      <td>0.073462</td>\n",
       "      <td>0.736023</td>\n",
       "      <td>0.201687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Otros</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>19</td>\n",
       "      <td>DEVON ST</td>\n",
       "      <td>42.308126</td>\n",
       "      <td>-71.076930</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517840</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.465558</td>\n",
       "      <td>0.473233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desorden</td>\n",
       "      <td>A1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>20</td>\n",
       "      <td>CAMBRIDGE ST</td>\n",
       "      <td>42.359454</td>\n",
       "      <td>-71.059648</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.518198</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.781170</td>\n",
       "      <td>0.553614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Otros</td>\n",
       "      <td>A7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>20</td>\n",
       "      <td>PRESCOTT ST</td>\n",
       "      <td>42.375258</td>\n",
       "      <td>-71.024663</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.518198</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.878350</td>\n",
       "      <td>0.716335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OFFENSE_CODE_GROUP DISTRICT  SHOOTING  YEAR  MONTH DAY_OF_WEEK  HOUR  \\\n",
       "0           Desorden      E18       0.0  2018     10   Wednesday    20   \n",
       "1              Otros      D14       0.0  2018      8    Thursday    20   \n",
       "2              Otros       B2       0.0  2018     10   Wednesday    19   \n",
       "3           Desorden       A1       0.0  2018     10   Wednesday    20   \n",
       "4              Otros       A7       0.0  2018     10   Wednesday    20   \n",
       "\n",
       "         STREET        Lat       Long  IS_NIGHT  DAY_OF_MONTH    TIME_X  \\\n",
       "0  ARLINGTON ST  42.262608 -71.121186         1             3  0.518198   \n",
       "1    ALLSTON ST  42.352111 -71.135311         1            30  0.239106   \n",
       "2      DEVON ST  42.308126 -71.076930         1             3  0.517840   \n",
       "3  CAMBRIDGE ST  42.359454 -71.059648         1             3  0.518198   \n",
       "4   PRESCOTT ST  42.375258 -71.024663         1             3  0.518198   \n",
       "\n",
       "     TIME_Y     Lat_M    Long_M  \n",
       "0  0.000331  0.185665  0.267386  \n",
       "1  0.073462  0.736023  0.201687  \n",
       "2  0.000318  0.465558  0.473233  \n",
       "3  0.000331  0.781170  0.553614  \n",
       "4  0.000331  0.878350  0.716335  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_time = pd.read_csv ('crimes_clean_time_2.csv', sep='\"\"', delimiter=',', engine='python')\n",
    "crimes_time.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_CODE_GROUP</th>\n",
       "      <th>SHOOTING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>IS_NIGHT</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lat_M</th>\n",
       "      <th>Long</th>\n",
       "      <th>Long_M</th>\n",
       "      <th>TIME_X</th>\n",
       "      <th>TIME_Y</th>\n",
       "      <th>DISTRICT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desorden</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>42.262608</td>\n",
       "      <td>0.185665</td>\n",
       "      <td>-71.121186</td>\n",
       "      <td>0.267386</td>\n",
       "      <td>0.518198</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>E18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Otros</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>42.352111</td>\n",
       "      <td>0.736023</td>\n",
       "      <td>-71.135311</td>\n",
       "      <td>0.201687</td>\n",
       "      <td>0.239106</td>\n",
       "      <td>0.073462</td>\n",
       "      <td>D14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Otros</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>42.308126</td>\n",
       "      <td>0.465558</td>\n",
       "      <td>-71.076930</td>\n",
       "      <td>0.473233</td>\n",
       "      <td>0.517840</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desorden</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>42.359454</td>\n",
       "      <td>0.781170</td>\n",
       "      <td>-71.059648</td>\n",
       "      <td>0.553614</td>\n",
       "      <td>0.518198</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Otros</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>42.375258</td>\n",
       "      <td>0.878350</td>\n",
       "      <td>-71.024663</td>\n",
       "      <td>0.716335</td>\n",
       "      <td>0.518198</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>A7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OFFENSE_CODE_GROUP  SHOOTING  YEAR  MONTH  DAY_OF_MONTH DAY_OF_WEEK  HOUR  \\\n",
       "0           Desorden       0.0  2018     10             3   Wednesday    20   \n",
       "1              Otros       0.0  2018      8            30    Thursday    20   \n",
       "2              Otros       0.0  2018     10             3   Wednesday    19   \n",
       "3           Desorden       0.0  2018     10             3   Wednesday    20   \n",
       "4              Otros       0.0  2018     10             3   Wednesday    20   \n",
       "\n",
       "   IS_NIGHT        Lat     Lat_M       Long    Long_M    TIME_X    TIME_Y  \\\n",
       "0         1  42.262608  0.185665 -71.121186  0.267386  0.518198  0.000331   \n",
       "1         1  42.352111  0.736023 -71.135311  0.201687  0.239106  0.073462   \n",
       "2         1  42.308126  0.465558 -71.076930  0.473233  0.517840  0.000318   \n",
       "3         1  42.359454  0.781170 -71.059648  0.553614  0.518198  0.000331   \n",
       "4         1  42.375258  0.878350 -71.024663  0.716335  0.518198  0.000331   \n",
       "\n",
       "  DISTRICT  \n",
       "0      E18  \n",
       "1      D14  \n",
       "2       B2  \n",
       "3       A1  \n",
       "4       A7  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_time=crimes_time[['OFFENSE_CODE_GROUP', 'SHOOTING','YEAR','MONTH','DAY_OF_MONTH','DAY_OF_WEEK','HOUR','IS_NIGHT','Lat', 'Lat_M', 'Long','Long_M', 'TIME_X', 'TIME_Y', 'DISTRICT']]\n",
    "crimes_time.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_CODE_GROUP</th>\n",
       "      <th>SHOOTING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>IS_NIGHT</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lat_M</th>\n",
       "      <th>Long</th>\n",
       "      <th>Long_M</th>\n",
       "      <th>TIME_X</th>\n",
       "      <th>TIME_Y</th>\n",
       "      <th>DISTRICT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127685</th>\n",
       "      <td>Sexual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.291093</td>\n",
       "      <td>0.360820</td>\n",
       "      <td>-71.065945</td>\n",
       "      <td>0.524324</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.648202</td>\n",
       "      <td>C11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242709</th>\n",
       "      <td>Otros</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.283634</td>\n",
       "      <td>0.314958</td>\n",
       "      <td>-71.082813</td>\n",
       "      <td>0.445868</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.648202</td>\n",
       "      <td>B3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290054</th>\n",
       "      <td>Fraude</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.360205</td>\n",
       "      <td>0.785788</td>\n",
       "      <td>-71.056208</td>\n",
       "      <td>0.569614</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.648202</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297104</th>\n",
       "      <td>Otros</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.293606</td>\n",
       "      <td>0.376273</td>\n",
       "      <td>-71.071887</td>\n",
       "      <td>0.496690</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.648202</td>\n",
       "      <td>C11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301293</th>\n",
       "      <td>Hurto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.300217</td>\n",
       "      <td>0.416923</td>\n",
       "      <td>-71.080979</td>\n",
       "      <td>0.454397</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.648202</td>\n",
       "      <td>B3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       OFFENSE_CODE_GROUP  SHOOTING  YEAR  MONTH  DAY_OF_MONTH DAY_OF_WEEK  \\\n",
       "127685             Sexual       0.0  2015      6            15      Monday   \n",
       "242709              Otros       0.0  2015      6            15      Monday   \n",
       "290054             Fraude       0.0  2015      6            15      Monday   \n",
       "297104              Otros       0.0  2015      6            15      Monday   \n",
       "301293              Hurto       0.0  2015      6            15      Monday   \n",
       "\n",
       "        HOUR  IS_NIGHT        Lat     Lat_M       Long    Long_M    TIME_X  \\\n",
       "127685     0         1  42.291093  0.360820 -71.065945  0.524324  0.022469   \n",
       "242709     0         1  42.283634  0.314958 -71.082813  0.445868  0.022469   \n",
       "290054     0         1  42.360205  0.785788 -71.056208  0.569614  0.022469   \n",
       "297104     0         1  42.293606  0.376273 -71.071887  0.496690  0.022469   \n",
       "301293     0         1  42.300217  0.416923 -71.080979  0.454397  0.022469   \n",
       "\n",
       "          TIME_Y DISTRICT  \n",
       "127685  0.648202      C11  \n",
       "242709  0.648202       B3  \n",
       "290054  0.648202       A1  \n",
       "297104  0.648202      C11  \n",
       "301293  0.648202       B3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_times = crimes_time.sort_values(['YEAR', 'MONTH', 'DAY_OF_MONTH', 'HOUR'], ascending=[True, True, True, True])\n",
    "crimes_times.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_time_one = crimes_time\n",
    "le_dw = LabelEncoder()\n",
    "dw_labels = le_dw.fit_transform(crimes_time_one['DAY_OF_WEEK'])\n",
    "crimes_time_one['DAY_OF_WEEK_label'] = dw_labels\n",
    "\n",
    "one_dw = OneHotEncoder()\n",
    "days_of_week = one_dw.fit_transform(crimes_time_one[['DAY_OF_WEEK_label']]).toarray()\n",
    "days_of_week_labels = list(le_dw.classes_)\n",
    "days_of_week_df = pd.DataFrame(days_of_week, columns=days_of_week_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_ocg = LabelEncoder()\n",
    "ocg_labels = le_ocg.fit_transform(crimes_time_one['OFFENSE_CODE_GROUP'])\n",
    "crimes_time_one['OFFENSE_CODE_label'] = ocg_labels\n",
    "\n",
    "one_ocg = OneHotEncoder()\n",
    "ocg = one_ocg.fit_transform(crimes_time_one[['OFFENSE_CODE_label']]).toarray()\n",
    "ocg_labels = list(le_ocg.classes_)\n",
    "ocg_df = pd.DataFrame(ocg, columns=ocg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le_year = LabelEncoder()\n",
    "#year_labels = le_year.fit_transform(crimes_time_one['YEAR'])\n",
    "#crimes_time_one['year_label'] = year_labels\n",
    "\n",
    "#one_year = OneHotEncoder()\n",
    "#year = one_year.fit_transform(crimes_time_one[['year_label']]).toarray()\n",
    "#year_labels = list(le_year.classes_)\n",
    "#year_df = pd.DataFrame(year, columns=year_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_d = LabelEncoder()\n",
    "d_labels = le_d.fit_transform(crimes_time_one['DISTRICT'])\n",
    "crimes_time_one['DISTRICT_labels'] = d_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_time_one = pd.concat([ocg_df,days_of_week_df, crimes_time_one], axis=1)\n",
    "\n",
    "crimes_time_one.drop('DAY_OF_WEEK_label', 1, inplace= True)\n",
    "crimes_time_one.drop('OFFENSE_CODE_label', 1, inplace= True)\n",
    "crimes_time_one.drop('DAY_OF_WEEK', 1, inplace= True)\n",
    "crimes_time_one.drop('OFFENSE_CODE_GROUP', 1, inplace= True)\n",
    "#crimes_time_one.drop('year_label', 1, inplace= True)\n",
    "crimes_time_one.drop('DISTRICT', 1, inplace= True)\n",
    "crimes_time_one.drop('Lat', 1, inplace= True)\n",
    "crimes_time_one.drop('Long', 1, inplace= True)\n",
    "crimes_time_one.drop('Lat_M', 1, inplace= True)\n",
    "crimes_time_one.drop('Long_M', 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "crimes_time_one = crimes_time_one.sort_values(['YEAR', 'MONTH', 'DAY_OF_MONTH', 'HOUR'], ascending=[True, True, True, True])\n",
    "crimes_time_train_test = crimes_time_one.head(int(crimes_time_one.shape[0] * 0.8))\n",
    "crimes_time_validation = crimes_time_one.tail(crimes_time_one.shape[0] - int(crimes_times.shape[0] * 0.8))\n",
    "crimes_time_train_test.drop('YEAR', 1, inplace= True)\n",
    "crimes_time_validation.drop('YEAR', 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Armas</th>\n",
       "      <th>Asesinato</th>\n",
       "      <th>Desaparecido</th>\n",
       "      <th>Desorden</th>\n",
       "      <th>Drogas</th>\n",
       "      <th>Falsificacion</th>\n",
       "      <th>Fraude</th>\n",
       "      <th>Hurto</th>\n",
       "      <th>Infancia</th>\n",
       "      <th>Investigar</th>\n",
       "      <th>...</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>SHOOTING</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>IS_NIGHT</th>\n",
       "      <th>TIME_X</th>\n",
       "      <th>TIME_Y</th>\n",
       "      <th>DISTRICT_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127685</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.648202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242709</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.648202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290054</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.648202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.648202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301293</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.648202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Armas  Asesinato  Desaparecido  Desorden  Drogas  Falsificacion  \\\n",
       "127685    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "242709    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "290054    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "297104    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "301293    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "\n",
       "        Fraude  Hurto  Infancia  Investigar  ...  Tuesday  Wednesday  \\\n",
       "127685     0.0    0.0       0.0         0.0  ...      0.0        0.0   \n",
       "242709     0.0    0.0       0.0         0.0  ...      0.0        0.0   \n",
       "290054     1.0    0.0       0.0         0.0  ...      0.0        0.0   \n",
       "297104     0.0    0.0       0.0         0.0  ...      0.0        0.0   \n",
       "301293     0.0    1.0       0.0         0.0  ...      0.0        0.0   \n",
       "\n",
       "        SHOOTING  MONTH  DAY_OF_MONTH  HOUR  IS_NIGHT    TIME_X    TIME_Y  \\\n",
       "127685       0.0      6            15     0         1  0.022469  0.648202   \n",
       "242709       0.0      6            15     0         1  0.022469  0.648202   \n",
       "290054       0.0      6            15     0         1  0.022469  0.648202   \n",
       "297104       0.0      6            15     0         1  0.022469  0.648202   \n",
       "301293       0.0      6            15     0         1  0.022469  0.648202   \n",
       "\n",
       "        DISTRICT_labels  \n",
       "127685                5  \n",
       "242709                4  \n",
       "290054                0  \n",
       "297104                5  \n",
       "301293                4  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_time_train_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Armas</th>\n",
       "      <th>Asesinato</th>\n",
       "      <th>Desaparecido</th>\n",
       "      <th>Desorden</th>\n",
       "      <th>Drogas</th>\n",
       "      <th>Falsificacion</th>\n",
       "      <th>Fraude</th>\n",
       "      <th>Hurto</th>\n",
       "      <th>Infancia</th>\n",
       "      <th>Investigar</th>\n",
       "      <th>...</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>SHOOTING</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>IS_NIGHT</th>\n",
       "      <th>TIME_X</th>\n",
       "      <th>TIME_Y</th>\n",
       "      <th>DISTRICT_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61632</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918534</td>\n",
       "      <td>0.773549</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61649</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918534</td>\n",
       "      <td>0.773549</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61654</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918534</td>\n",
       "      <td>0.773549</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61655</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918534</td>\n",
       "      <td>0.773549</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61658</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918534</td>\n",
       "      <td>0.773549</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Armas  Asesinato  Desaparecido  Desorden  Drogas  Falsificacion  \\\n",
       "61632    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "61649    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "61654    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "61655    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "61658    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "\n",
       "       Fraude  Hurto  Infancia  Investigar  ...  Tuesday  Wednesday  SHOOTING  \\\n",
       "61632     0.0    0.0       0.0         0.0  ...      0.0        0.0       0.0   \n",
       "61649     0.0    0.0       0.0         0.0  ...      0.0        0.0       0.0   \n",
       "61654     0.0    0.0       0.0         0.0  ...      0.0        0.0       0.0   \n",
       "61655     0.0    1.0       0.0         0.0  ...      0.0        0.0       0.0   \n",
       "61658     0.0    0.0       0.0         0.0  ...      0.0        0.0       0.0   \n",
       "\n",
       "       MONTH  DAY_OF_MONTH  HOUR  IS_NIGHT    TIME_X    TIME_Y  \\\n",
       "61632      2             3    15         0  0.918534  0.773549   \n",
       "61649      2             3    15         0  0.918534  0.773549   \n",
       "61654      2             3    15         0  0.918534  0.773549   \n",
       "61655      2             3    15         0  0.918534  0.773549   \n",
       "61658      2             3    15         0  0.918534  0.773549   \n",
       "\n",
       "       DISTRICT_labels  \n",
       "61632                5  \n",
       "61649                1  \n",
       "61654                6  \n",
       "61655                6  \n",
       "61658               10  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_time_validation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61104, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_time_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244416, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_time_train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(crimes_time_train_test.loc[:,'Armas':'TIME_Y'], crimes_time_train_test.loc[:,'DISTRICT_labels'], test_size = 0.25, random_state = 0)\n",
    "#xTrain, xTest, yTrain, yTest = train_test_split(crimes_time_train_test.loc[:,'OFFENSE_CODE_GROUP':'TIME_Y'], crimes_time_train_test.loc[:,'DISTRICT'], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xTrain.drop([ 'TIME_X', 'TIME_Y'], 1, inplace= True)\n",
    "#xTest.drop([ 'TIME_X', 'TIME_Y'], 1, inplace= True)\n",
    "xTrain.drop([ 'MONTH', 'DAY_OF_MONTH', 'HOUR'], 1, inplace= True)\n",
    "xTest.drop([ 'MONTH', 'DAY_OF_MONTH', 'HOUR'], 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Armas</th>\n",
       "      <th>Asesinato</th>\n",
       "      <th>Desaparecido</th>\n",
       "      <th>Desorden</th>\n",
       "      <th>Drogas</th>\n",
       "      <th>Falsificacion</th>\n",
       "      <th>Fraude</th>\n",
       "      <th>Hurto</th>\n",
       "      <th>Infancia</th>\n",
       "      <th>Investigar</th>\n",
       "      <th>...</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>SHOOTING</th>\n",
       "      <th>IS_NIGHT</th>\n",
       "      <th>TIME_X</th>\n",
       "      <th>TIME_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212312</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011357</td>\n",
       "      <td>0.605961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142481</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554321</td>\n",
       "      <td>0.997040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.245870</td>\n",
       "      <td>0.069398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.496772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197659</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140833</td>\n",
       "      <td>0.152151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197086</td>\n",
       "      <td>0.102202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251384</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986711</td>\n",
       "      <td>0.614509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127959</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119590</td>\n",
       "      <td>0.824482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141817</td>\n",
       "      <td>0.151137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191587</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.302623</td>\n",
       "      <td>0.040606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.311043</td>\n",
       "      <td>0.962920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297915</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.395857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190360</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.344437</td>\n",
       "      <td>0.024816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304643</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016080</td>\n",
       "      <td>0.625783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031379</td>\n",
       "      <td>0.674339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Armas  Asesinato  Desaparecido  Desorden  Drogas  Falsificacion  \\\n",
       "212312    0.0        0.0           0.0       1.0     0.0            0.0   \n",
       "142481    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "100391    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "254792    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "197659    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "102119    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "251384    0.0        0.0           0.0       1.0     0.0            0.0   \n",
       "127959    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "289106    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "191587    0.0        0.0           0.0       1.0     0.0            0.0   \n",
       "135199    0.0        0.0           0.0       1.0     0.0            0.0   \n",
       "297915    0.0        0.0           0.0       0.0     1.0            0.0   \n",
       "190360    0.0        0.0           0.0       1.0     0.0            0.0   \n",
       "304643    0.0        0.0           0.0       0.0     0.0            0.0   \n",
       "122678    0.0        0.0           0.0       0.0     1.0            0.0   \n",
       "\n",
       "        Fraude  Hurto  Infancia  Investigar  ...  Monday  Saturday  Sunday  \\\n",
       "212312     0.0    0.0       0.0         0.0  ...     0.0       0.0     1.0   \n",
       "142481     0.0    0.0       0.0         0.0  ...     0.0       0.0     1.0   \n",
       "100391     0.0    1.0       0.0         0.0  ...     0.0       0.0     0.0   \n",
       "254792     0.0    0.0       0.0         0.0  ...     0.0       0.0     0.0   \n",
       "197659     0.0    1.0       0.0         0.0  ...     1.0       0.0     0.0   \n",
       "102119     0.0    0.0       0.0         0.0  ...     0.0       0.0     0.0   \n",
       "251384     0.0    0.0       0.0         0.0  ...     0.0       0.0     0.0   \n",
       "127959     0.0    0.0       0.0         1.0  ...     1.0       0.0     0.0   \n",
       "289106     0.0    0.0       0.0         0.0  ...     0.0       0.0     1.0   \n",
       "191587     0.0    0.0       0.0         0.0  ...     0.0       0.0     0.0   \n",
       "135199     0.0    0.0       0.0         0.0  ...     1.0       0.0     0.0   \n",
       "297915     0.0    0.0       0.0         0.0  ...     0.0       0.0     0.0   \n",
       "190360     0.0    0.0       0.0         0.0  ...     0.0       0.0     0.0   \n",
       "304643     0.0    0.0       0.0         1.0  ...     0.0       0.0     0.0   \n",
       "122678     0.0    0.0       0.0         0.0  ...     0.0       0.0     1.0   \n",
       "\n",
       "        Thursday  Tuesday  Wednesday  SHOOTING  IS_NIGHT    TIME_X    TIME_Y  \n",
       "212312       0.0      0.0        0.0       0.0         0  0.011357  0.605961  \n",
       "142481       0.0      0.0        0.0       0.0         1  0.554321  0.997040  \n",
       "100391       1.0      0.0        0.0       0.0         0  0.245870  0.069398  \n",
       "254792       1.0      0.0        0.0       0.0         0  0.999990  0.496772  \n",
       "197659       0.0      0.0        0.0       0.0         0  0.140833  0.152151  \n",
       "102119       1.0      0.0        0.0       0.0         1  0.197086  0.102202  \n",
       "251384       1.0      0.0        0.0       0.0         0  0.986711  0.614509  \n",
       "127959       0.0      0.0        0.0       0.0         0  0.119590  0.824482  \n",
       "289106       0.0      0.0        0.0       0.0         0  0.141817  0.151137  \n",
       "191587       0.0      0.0        1.0       0.0         1  0.302623  0.040606  \n",
       "135199       0.0      0.0        0.0       0.0         0  0.311043  0.962920  \n",
       "297915       0.0      1.0        0.0       0.0         0  0.010966  0.395857  \n",
       "190360       0.0      1.0        0.0       0.0         1  0.344437  0.024816  \n",
       "304643       0.0      0.0        1.0       0.0         0  0.016080  0.625783  \n",
       "122678       0.0      0.0        0.0       0.0         0  0.031379  0.674339  \n",
       "\n",
       "[15 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model (type_layer= 'LSTM', n_layers=1, n_embeding = 32,n_epochs = 20,batch_size=512 ):\n",
    "    \n",
    "    layer_r = tf.keras.layers.LSTM(n_embeding, return_sequences=True)\n",
    "    layer_e = tf.keras.layers.LSTM(n_embeding)\n",
    "    if type_layer == 'GRU':\n",
    "        layer_r = tf.keras.layers.GRU(n_embeding, return_sequences=True)\n",
    "        layer_e = tf.keras.layers.GRU(n_embeding)\n",
    "        \n",
    "    model_i = tf.keras.models.Sequential()\n",
    "    model_i.add(tf.keras.layers.Embedding(30, n_embeding, input_length=27))\n",
    "    if n_layers != 0:\n",
    "            model_i.add(layer_r)\n",
    "    \n",
    "    model_i.add(layer_e)\n",
    "    \n",
    "    model_i.add(tf.keras.layers.Dense(12))\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "    model_i.compile (optimizer=optimizer,loss='sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
    "    \n",
    "    return model_i.fit(xTrain, yTrain, epochs = n_epochs,batch_size=batch_size, validation_data=(xTest, yTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/20\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 3.1297 - accuracy: 0.0483 - val_loss: 3.0661 - val_accuracy: 0.0208\n",
      "Epoch 2/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 3.0467 - accuracy: 0.0805 - val_loss: 3.0414 - val_accuracy: 0.1113\n",
      "Epoch 3/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 3.0240 - accuracy: 0.1408 - val_loss: 3.0771 - val_accuracy: 0.1396\n",
      "Epoch 4/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 3.1270 - accuracy: 0.1319 - val_loss: 3.1259 - val_accuracy: 0.1586\n",
      "Epoch 5/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 3.1787 - accuracy: 0.1394 - val_loss: 3.1435 - val_accuracy: 0.1586\n",
      "Epoch 6/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 3.1014 - accuracy: 0.1466 - val_loss: 3.2123 - val_accuracy: 0.0644\n",
      "Epoch 7/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 3.0866 - accuracy: 0.1419 - val_loss: 3.1380 - val_accuracy: 0.0725\n",
      "Epoch 8/20\n",
      "183312/183312 [==============================] - 5s 26us/sample - loss: 3.1271 - accuracy: 0.1346 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 9/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 10/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 11/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 12/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 13/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 14/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 15/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 16/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 17/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 18/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 19/20\n",
      "183312/183312 [==============================] - 5s 25us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n",
      "Epoch 20/20\n",
      "183312/183312 [==============================] - 5s 26us/sample - loss: 2.4849 - accuracy: 0.1074 - val_loss: 2.4849 - val_accuracy: 0.1077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c4d774c0c8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model (type_layer= 'LSTM', n_layers=0, n_embeding = 128,n_epochs = 20,batch_size=256 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "0\n",
      "64\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 7s 39us/sample - loss: 2.7769 - accuracy: 0.1309 - val_loss: 2.3560 - val_accuracy: 0.1474\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 2.3569 - accuracy: 0.1533 - val_loss: 2.3566 - val_accuracy: 0.1396\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 2.3571 - accuracy: 0.1465 - val_loss: 2.3542 - val_accuracy: 0.1586\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 2.3614 - accuracy: 0.1533 - val_loss: 2.3556 - val_accuracy: 0.1587\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 2.3557 - accuracy: 0.1515 - val_loss: 2.3511 - val_accuracy: 0.1587\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 2.3574 - accuracy: 0.1541 - val_loss: 2.3593 - val_accuracy: 0.1586\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 2.3537 - accuracy: 0.1541 - val_loss: 2.3478 - val_accuracy: 0.1593\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 2.3492 - accuracy: 0.1553 - val_loss: 2.3565 - val_accuracy: 0.1585\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.3540 - accuracy: 0.1550 - val_loss: 2.3660 - val_accuracy: 0.1586\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.3563 - accuracy: 0.1553 - val_loss: 2.3493 - val_accuracy: 0.1586\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 2.3557 - accuracy: 0.1553 - val_loss: 2.3550 - val_accuracy: 0.1586\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 2.3509 - accuracy: 0.1551 - val_loss: 2.3443 - val_accuracy: 0.1585\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.4202 - accuracy: 0.1551 - val_loss: 3.8646 - val_accuracy: 0.1586\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.9069 - accuracy: 0.1551 - val_loss: 3.8837 - val_accuracy: 0.1586\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 3.9135 - accuracy: 0.1549 - val_loss: 3.8836 - val_accuracy: 0.1586\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 3.9046 - accuracy: 0.1553 - val_loss: 3.8739 - val_accuracy: 0.1586\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.9029 - accuracy: 0.1552 - val_loss: 3.8737 - val_accuracy: 0.1586\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.9025 - accuracy: 0.1553 - val_loss: 3.8720 - val_accuracy: 0.1586\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.9027 - accuracy: 0.1553 - val_loss: 3.8755 - val_accuracy: 0.1586\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.9022 - accuracy: 0.1553 - val_loss: 3.8756 - val_accuracy: 0.1586\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.9065 - accuracy: 0.1553 - val_loss: 3.8833 - val_accuracy: 0.1587\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.9133 - accuracy: 0.1553 - val_loss: 3.8854 - val_accuracy: 0.1587\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.9134 - accuracy: 0.1550 - val_loss: 3.8834 - val_accuracy: 0.1584\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.9131 - accuracy: 0.1544 - val_loss: 3.8838 - val_accuracy: 0.1582\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.9140 - accuracy: 0.1259 - val_loss: 3.8834 - val_accuracy: 0.1116\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.8935 - accuracy: 0.1396 - val_loss: 3.8633 - val_accuracy: 0.1284\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 3.8771 - accuracy: 0.1349 - val_loss: 3.8482 - val_accuracy: 0.1238\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.8747 - accuracy: 0.1366 - val_loss: 3.8466 - val_accuracy: 0.1508\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.8750 - accuracy: 0.1286 - val_loss: 3.8467 - val_accuracy: 0.1113\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 6s 34us/sample - loss: 3.8753 - accuracy: 0.1481 - val_loss: 3.8464 - val_accuracy: 0.1586\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C4850A3348>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "0\n",
      "128\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 8s 42us/sample - loss: 3.9069 - accuracy: 0.1139 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 7s 37us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 7s 36us/sample - loss: 4.1291 - accuracy: 0.1135 - val_loss: 4.1318 - val_accuracy: 0.1113\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C4D7946188>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "0\n",
      "256\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 6.0701 - accuracy: 0.1305 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 10s 55us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 6.0494 - accuracy: 0.1306 - val_loss: 6.0351 - val_accuracy: 0.1274\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C485F39F88>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "0\n",
      "64\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 7s 39us/sample - loss: 2.6647 - accuracy: 0.1505 - val_loss: 2.6087 - val_accuracy: 0.1396\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5961 - accuracy: 0.1501 - val_loss: 2.5955 - val_accuracy: 0.1586\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5936 - accuracy: 0.1501 - val_loss: 2.5876 - val_accuracy: 0.1586\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5920 - accuracy: 0.1504 - val_loss: 2.5976 - val_accuracy: 0.1586\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5927 - accuracy: 0.1488 - val_loss: 2.5871 - val_accuracy: 0.1586\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5929 - accuracy: 0.1501 - val_loss: 2.5975 - val_accuracy: 0.1586\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5918 - accuracy: 0.1493 - val_loss: 2.5889 - val_accuracy: 0.1586\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5924 - accuracy: 0.1495 - val_loss: 2.5935 - val_accuracy: 0.1586\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5928 - accuracy: 0.1502 - val_loss: 2.5880 - val_accuracy: 0.1586\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5920 - accuracy: 0.1497 - val_loss: 2.5902 - val_accuracy: 0.1586\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5914 - accuracy: 0.1509 - val_loss: 2.5889 - val_accuracy: 0.1586\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5923 - accuracy: 0.1499 - val_loss: 2.5884 - val_accuracy: 0.1473\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5915 - accuracy: 0.1501 - val_loss: 2.5947 - val_accuracy: 0.1401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5905 - accuracy: 0.1496 - val_loss: 2.5877 - val_accuracy: 0.1396\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5924 - accuracy: 0.1505 - val_loss: 2.5880 - val_accuracy: 0.1478\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5915 - accuracy: 0.1507 - val_loss: 2.6052 - val_accuracy: 0.1475\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.5439 - accuracy: 0.0776 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 6s 35us/sample - loss: 2.4849 - accuracy: 0.0208 - val_loss: 2.4849 - val_accuracy: 0.0208\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C48950DC88>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "0\n",
      "128\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 9.0937 - accuracy: 0.1550 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 8s 43us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 8s 43us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 8s 43us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 8s 43us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 8s 43us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 8s 43us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 8s 43us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 8s 43us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 8s 43us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 8s 43us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 8s 43us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 9.0935 - accuracy: 0.1553 - val_loss: 9.0439 - val_accuracy: 0.1586\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C485339C88>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "0\n",
      "256\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 13.9478 - accuracy: 0.1305 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 11s 59us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 11s 59us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 11s 59us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 11s 59us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 11s 59us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 14.0052 - accuracy: 0.1306 - val_loss: 14.0555 - val_accuracy: 0.1274\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C4863D5F48>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "1\n",
      "64\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 2.5097 - accuracy: 0.0547 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C485891248>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "1\n",
      "128\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 4.3134 - accuracy: 0.1529 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.2726 - accuracy: 0.1553 - val_loss: 4.2727 - val_accuracy: 0.1586\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C48B258E88>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "1\n",
      "256\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 4.8883 - accuracy: 0.0562 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 4.8740 - accuracy: 0.0555 - val_loss: 4.8884 - val_accuracy: 0.0556\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C484F05CC8>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "1\n",
      "64\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 10s 57us/sample - loss: 3.4222 - accuracy: 0.0693 - val_loss: 3.2941 - val_accuracy: 0.0644\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 3.0325 - accuracy: 0.0536 - val_loss: 2.6873 - val_accuracy: 0.0414\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6927 - accuracy: 0.0433 - val_loss: 2.6949 - val_accuracy: 0.0414\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6952 - accuracy: 0.0433 - val_loss: 2.6953 - val_accuracy: 0.0414\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6949 - accuracy: 0.0433 - val_loss: 2.6966 - val_accuracy: 0.0414\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6952 - accuracy: 0.0433 - val_loss: 2.6948 - val_accuracy: 0.0414\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6947 - accuracy: 0.0433 - val_loss: 2.6970 - val_accuracy: 0.0414\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6952 - accuracy: 0.0433 - val_loss: 2.6938 - val_accuracy: 0.0414\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6949 - accuracy: 0.0433 - val_loss: 2.7006 - val_accuracy: 0.0414\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.6950 - accuracy: 0.1129 - val_loss: 2.6951 - val_accuracy: 0.1113\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6956 - accuracy: 0.1126 - val_loss: 2.6987 - val_accuracy: 0.1077\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.6947 - accuracy: 0.1074 - val_loss: 2.6939 - val_accuracy: 0.1077\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6947 - accuracy: 0.1074 - val_loss: 2.6968 - val_accuracy: 0.1077\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6945 - accuracy: 0.1074 - val_loss: 2.6942 - val_accuracy: 0.1077\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.6946 - accuracy: 0.1074 - val_loss: 2.6976 - val_accuracy: 0.1077\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.6945 - accuracy: 0.1074 - val_loss: 2.6955 - val_accuracy: 0.1077\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6946 - accuracy: 0.1074 - val_loss: 2.6995 - val_accuracy: 0.1077\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6947 - accuracy: 0.1074 - val_loss: 2.6954 - val_accuracy: 0.1077\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6945 - accuracy: 0.1074 - val_loss: 2.6966 - val_accuracy: 0.1077\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6947 - accuracy: 0.1074 - val_loss: 2.6963 - val_accuracy: 0.1077\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6945 - accuracy: 0.1074 - val_loss: 2.6947 - val_accuracy: 0.1077\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.6949 - accuracy: 0.1074 - val_loss: 2.6954 - val_accuracy: 0.1077\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6947 - accuracy: 0.1074 - val_loss: 2.6959 - val_accuracy: 0.1077\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6948 - accuracy: 0.1074 - val_loss: 2.6946 - val_accuracy: 0.1077\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6946 - accuracy: 0.1074 - val_loss: 2.6941 - val_accuracy: 0.1077\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6947 - accuracy: 0.1074 - val_loss: 2.6940 - val_accuracy: 0.1077\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6944 - accuracy: 0.1074 - val_loss: 2.6950 - val_accuracy: 0.1077\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.6945 - accuracy: 0.1074 - val_loss: 2.6987 - val_accuracy: 0.1077\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.6950 - accuracy: 0.1074 - val_loss: 2.6947 - val_accuracy: 0.1077\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.6948 - accuracy: 0.1074 - val_loss: 2.6950 - val_accuracy: 0.1077\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C48C7BD8C8>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "1\n",
      "128\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 13s 71us/sample - loss: 5.9031 - accuracy: 0.0561 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 5.8866 - accuracy: 0.0556 - val_loss: 5.8913 - val_accuracy: 0.0557\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C48A55F988>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "1\n",
      "256\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 18s 98us/sample - loss: 5.4615 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4557 - accuracy: 0.1074 - val_loss: 5.4679 - val_accuracy: 0.1077\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C48B6DBAC8>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "2\n",
      "64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 5.1311 - accuracy: 0.1386 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 8s 44us/sample - loss: 5.1086 - accuracy: 0.1387 - val_loss: 5.0583 - val_accuracy: 0.1396\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C4894F0E48>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "2\n",
      "128\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 10s 57us/sample - loss: 5.7613 - accuracy: 0.1070 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 9s 52us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.7224 - accuracy: 0.1074 - val_loss: 5.7383 - val_accuracy: 0.1077\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C485D0CD08>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "2\n",
      "256\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 16s 90us/sample - loss: 10.1171 - accuracy: 0.0450 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 15s 82us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 15s 82us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 16s 85us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 17s 91us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 17s 94us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 17s 91us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 15s 83us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 15s 82us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 15s 82us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 15s 84us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 15s 82us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 15s 82us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 15s 82us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 15s 83us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 10.1247 - accuracy: 0.0433 - val_loss: 10.1243 - val_accuracy: 0.0414\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C48AFDB548>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "2\n",
      "64\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 10s 56us/sample - loss: 5.5043 - accuracy: 0.0679 - val_loss: 2.7062 - val_accuracy: 0.0571\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 2.7329 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.7336 - accuracy: 0.0546 - val_loss: 2.7329 - val_accuracy: 0.0571\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C488FD9548>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "2\n",
      "128\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 13s 71us/sample - loss: 6.6608 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 12s 64us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 12s 67us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 13s 70us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 13s 71us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 13s 69us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 12s 67us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 12s 66us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 12s 64us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 12s 64us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 11s 61us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 11s 61us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 11s 61us/sample - loss: 6.6550 - accuracy: 0.0721 - val_loss: 6.6243 - val_accuracy: 0.0724\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C48697E448>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "2\n",
      "256\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 17s 95us/sample - loss: 7.8712 - accuracy: 0.0434 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 16s 87us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 16s 87us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 16s 87us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 16s 87us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 17s 90us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 18s 98us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 17s 93us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 16s 90us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 18s 100us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 17s 91us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 18s 96us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 19s 102us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 18s 100us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 17s 91us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 17s 91us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 18s 97us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 19s 104us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 19s 104us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 19s 103us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 18s 96us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 18s 100us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 19s 102us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 19s 103us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 19s 102us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 18s 98us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 18s 100us/sample - loss: 7.8716 - accuracy: 0.0433 - val_loss: 7.8672 - val_accuracy: 0.0414\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C4859C8488>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "3\n",
      "64\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 11s 57us/sample - loss: 5.1869 - accuracy: 0.0439 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 8s 46us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 9s 52us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 9s 52us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 8s 46us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 9s 46us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 8s 46us/sample - loss: 5.1413 - accuracy: 0.0433 - val_loss: 5.1942 - val_accuracy: 0.0414\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C4985C2948>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "3\n",
      "128\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 11s 60us/sample - loss: 2.5138 - accuracy: 0.0548 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 9s 52us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 12s 66us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 11s 60us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 10s 55us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 11s 59us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 10s 57us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 10s 55us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 10s 55us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 10s 54us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 10s 53us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 2.4849 - accuracy: 0.0546 - val_loss: 2.4849 - val_accuracy: 0.0571\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C4851BC508>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "3\n",
      "256\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 17s 92us/sample - loss: 11.0620 - accuracy: 0.1537 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 16s 87us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 15s 83us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 15s 83us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 16s 85us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 17s 93us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 15s 83us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 15s 84us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 15s 84us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 16s 85us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 16s 86us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 15s 84us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 15s 83us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183312/183312 [==============================] - 15s 82us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 16s 85us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 16s 87us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 16s 86us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 15s 84us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 16s 85us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 15s 82us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 15s 82us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 15s 84us/sample - loss: 11.0676 - accuracy: 0.1553 - val_loss: 11.0059 - val_accuracy: 0.1586\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C4809B7288>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "3\n",
      "64\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 3.3300 - accuracy: 0.0643 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 10s 52us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 9s 52us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.4849 - accuracy: 0.0556 - val_loss: 2.4849 - val_accuracy: 0.0557\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C48FBA6C48>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "3\n",
      "128\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 13s 73us/sample - loss: 4.6811 - accuracy: 0.0973 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 12s 64us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 3.2938 - accuracy: 0.0434 - val_loss: 3.2950 - val_accuracy: 0.0436\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C486B25148>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "3\n",
      "256\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 18s 97us/sample - loss: 5.4980 - accuracy: 0.0645 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 17s 90us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 17s 92us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 17s 92us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 19s 104us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183312/183312 [==============================] - 18s 100us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 17s 94us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 18s 100us/sample - loss: 5.4689 - accuracy: 0.0628 - val_loss: 5.4855 - val_accuracy: 0.0605\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C49651B888>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "4\n",
      "64\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 11s 59us/sample - loss: 6.0729 - accuracy: 0.1115 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 8s 46us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 8s 46us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 8s 46us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 8s 46us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 8s 46us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 8s 46us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 8s 45us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 8s 46us/sample - loss: 5.8821 - accuracy: 0.1135 - val_loss: 5.8562 - val_accuracy: 0.1113\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C480A567C8>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "4\n",
      "128\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 11s 57us/sample - loss: 4.9234 - accuracy: 0.1075 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 9s 51us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 9s 50us/sample - loss: 4.9009 - accuracy: 0.1074 - val_loss: 4.9545 - val_accuracy: 0.1077\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C485094F48>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "GRU\n",
      "4\n",
      "256\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 6.9981 - accuracy: 0.0435 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 15s 83us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 15s 81us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 15s 80us/sample - loss: 6.9931 - accuracy: 0.0433 - val_loss: 7.0514 - val_accuracy: 0.0414\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C48BD20148>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "4\n",
      "64\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 11s 58us/sample - loss: 2.7135 - accuracy: 0.1025 - val_loss: 2.6971 - val_accuracy: 0.0571\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.6549 - accuracy: 0.1314 - val_loss: 2.6345 - val_accuracy: 0.1396\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.6355 - accuracy: 0.1363 - val_loss: 2.6362 - val_accuracy: 0.1274\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.6310 - accuracy: 0.1387 - val_loss: 2.6203 - val_accuracy: 0.1586\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.6012 - accuracy: 0.1499 - val_loss: 2.6020 - val_accuracy: 0.1586\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.5945 - accuracy: 0.1508 - val_loss: 2.6088 - val_accuracy: 0.1586\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.5932 - accuracy: 0.1506 - val_loss: 2.5903 - val_accuracy: 0.1412\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.5940 - accuracy: 0.1494 - val_loss: 2.5924 - val_accuracy: 0.1274\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.5937 - accuracy: 0.1503 - val_loss: 2.5863 - val_accuracy: 0.1586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5926 - accuracy: 0.1487 - val_loss: 2.5855 - val_accuracy: 0.1586\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.5937 - accuracy: 0.1500 - val_loss: 2.5911 - val_accuracy: 0.1586\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5925 - accuracy: 0.1501 - val_loss: 2.5859 - val_accuracy: 0.1586\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5920 - accuracy: 0.1491 - val_loss: 2.5857 - val_accuracy: 0.1396\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5922 - accuracy: 0.1493 - val_loss: 2.5862 - val_accuracy: 0.1586\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5923 - accuracy: 0.1498 - val_loss: 2.5905 - val_accuracy: 0.1586\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5932 - accuracy: 0.1496 - val_loss: 2.5942 - val_accuracy: 0.1586\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5928 - accuracy: 0.1482 - val_loss: 2.5841 - val_accuracy: 0.1586\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.5929 - accuracy: 0.1497 - val_loss: 2.5926 - val_accuracy: 0.1396\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5922 - accuracy: 0.1500 - val_loss: 2.5891 - val_accuracy: 0.1586\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.5920 - accuracy: 0.1493 - val_loss: 2.5939 - val_accuracy: 0.1396\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.5914 - accuracy: 0.1487 - val_loss: 2.5950 - val_accuracy: 0.1586\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.5928 - accuracy: 0.1500 - val_loss: 2.6009 - val_accuracy: 0.1586\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5926 - accuracy: 0.1492 - val_loss: 2.5937 - val_accuracy: 0.1113\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5936 - accuracy: 0.1494 - val_loss: 2.5936 - val_accuracy: 0.1586\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5926 - accuracy: 0.1500 - val_loss: 2.5914 - val_accuracy: 0.1586\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5925 - accuracy: 0.1488 - val_loss: 2.5930 - val_accuracy: 0.1274\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5919 - accuracy: 0.1500 - val_loss: 2.5897 - val_accuracy: 0.1586\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 9s 47us/sample - loss: 2.5921 - accuracy: 0.1506 - val_loss: 2.5938 - val_accuracy: 0.1113\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 9s 49us/sample - loss: 2.5926 - accuracy: 0.1502 - val_loss: 2.5891 - val_accuracy: 0.1586\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 9s 48us/sample - loss: 2.5926 - accuracy: 0.1511 - val_loss: 2.5896 - val_accuracy: 0.1586\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C486D8C108>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "4\n",
      "128\n",
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 13s 71us/sample - loss: 2.5485 - accuracy: 0.1381 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 12s 64us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 12s 64us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 11s 62us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 12s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 11s 63us/sample - loss: 2.4849 - accuracy: 0.1387 - val_loss: 2.4849 - val_accuracy: 0.1396\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C485263AC8>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n",
      "************ NUEVA PRUEBA *************\n",
      "LSTM\n",
      "4\n",
      "256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/30\n",
      "183312/183312 [==============================] - 18s 99us/sample - loss: 11.1927 - accuracy: 0.1383 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 2/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 3/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 4/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 5/30\n",
      "183312/183312 [==============================] - 16s 90us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 6/30\n",
      "183312/183312 [==============================] - 17s 90us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 7/30\n",
      "183312/183312 [==============================] - 17s 91us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 8/30\n",
      "183312/183312 [==============================] - 17s 93us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 9/30\n",
      "183312/183312 [==============================] - 17s 91us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 10/30\n",
      "183312/183312 [==============================] - 16s 87us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 11/30\n",
      "183312/183312 [==============================] - 16s 87us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 12/30\n",
      "183312/183312 [==============================] - 16s 87us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 13/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 14/30\n",
      "183312/183312 [==============================] - 16s 87us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 15/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 16/30\n",
      "183312/183312 [==============================] - 18s 96us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 17/30\n",
      "183312/183312 [==============================] - 17s 90us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 18/30\n",
      "183312/183312 [==============================] - 17s 93us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 19/30\n",
      "183312/183312 [==============================] - 17s 92us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 20/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 21/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 22/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 23/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 24/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 25/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 26/30\n",
      "183312/183312 [==============================] - 16s 88us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 27/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 28/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 29/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "Epoch 30/30\n",
      "183312/183312 [==============================] - 16s 89us/sample - loss: 11.1875 - accuracy: 0.1387 - val_loss: 11.2185 - val_accuracy: 0.1396\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001C4863B3C88>\n",
      "0\n",
      "Imposible entrenar el modelos con los parametros siguientes\n"
     ]
    }
   ],
   "source": [
    "def grid_search(n_layers=[0,1,2,3,4], type_layers= ['GRU','LSTM'], n_embedings=[64,128,256], n_epochs = 30):\n",
    "    i=0\n",
    "    lista = {}\n",
    "    for n_layer in n_layers:\n",
    "        for type_l in type_layers:\n",
    "            for n_embeding in n_embedings:\n",
    "                print(\"************ NUEVA PRUEBA *************\")\n",
    "                print (type_l)\n",
    "                print (n_layer)\n",
    "                print (n_embeding)\n",
    "                try:\n",
    "                    fit = create_model (type_layer= type_l, n_layers=n_layer, n_embeding = n_embeding, n_epochs=n_epochs, batch_size=128)\n",
    "                    print(fit)\n",
    "                    print(i)\n",
    "                    lista[str(i)] = \"type_l=\" + type_l + \",n_layer=\"+ str(n_layer) + \",n_embeding\" + str(n_embeding) + \",lon=\" + str(lon)\n",
    "                    i=i+1\n",
    "                except:\n",
    "                    print(\"Imposible entrenar el modelos con los parametros siguientes\")\n",
    "    return lista\n",
    "\n",
    "resultados = grid_search ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/50\n",
      "183312/183312 [==============================] - 3s 16us/sample - loss: 2.3323 - accuracy: 0.1710 - val_loss: 2.3261 - val_accuracy: 0.1753\n",
      "Epoch 2/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3256 - accuracy: 0.1754 - val_loss: 2.3261 - val_accuracy: 0.1775\n",
      "Epoch 3/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3238 - accuracy: 0.1754 - val_loss: 2.3238 - val_accuracy: 0.1788\n",
      "Epoch 4/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3227 - accuracy: 0.1762 - val_loss: 2.3240 - val_accuracy: 0.1785\n",
      "Epoch 5/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3214 - accuracy: 0.1774 - val_loss: 2.3237 - val_accuracy: 0.1795\n",
      "Epoch 6/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3202 - accuracy: 0.1776 - val_loss: 2.3234 - val_accuracy: 0.1793\n",
      "Epoch 7/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3189 - accuracy: 0.1779 - val_loss: 2.3228 - val_accuracy: 0.1779\n",
      "Epoch 8/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3176 - accuracy: 0.1783 - val_loss: 2.3245 - val_accuracy: 0.1768\n",
      "Epoch 9/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3165 - accuracy: 0.1792 - val_loss: 2.3240 - val_accuracy: 0.1783\n",
      "Epoch 10/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3154 - accuracy: 0.1797 - val_loss: 2.3239 - val_accuracy: 0.1770\n",
      "Epoch 11/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3139 - accuracy: 0.1793 - val_loss: 2.3253 - val_accuracy: 0.1771\n",
      "Epoch 12/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3128 - accuracy: 0.1817 - val_loss: 2.3253 - val_accuracy: 0.1774\n",
      "Epoch 13/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3114 - accuracy: 0.1814 - val_loss: 2.3266 - val_accuracy: 0.1782\n",
      "Epoch 14/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3102 - accuracy: 0.1831 - val_loss: 2.3264 - val_accuracy: 0.1760\n",
      "Epoch 15/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3091 - accuracy: 0.1825 - val_loss: 2.3279 - val_accuracy: 0.1766\n",
      "Epoch 16/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3078 - accuracy: 0.1823 - val_loss: 2.3271 - val_accuracy: 0.1750\n",
      "Epoch 17/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3064 - accuracy: 0.1829 - val_loss: 2.3285 - val_accuracy: 0.1762\n",
      "Epoch 18/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3053 - accuracy: 0.1837 - val_loss: 2.3286 - val_accuracy: 0.1757\n",
      "Epoch 19/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3042 - accuracy: 0.1838 - val_loss: 2.3317 - val_accuracy: 0.1779\n",
      "Epoch 20/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3031 - accuracy: 0.1846 - val_loss: 2.3317 - val_accuracy: 0.1762\n",
      "Epoch 21/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3020 - accuracy: 0.1849 - val_loss: 2.3320 - val_accuracy: 0.1752\n",
      "Epoch 22/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3009 - accuracy: 0.1855 - val_loss: 2.3318 - val_accuracy: 0.1740\n",
      "Epoch 23/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2998 - accuracy: 0.1859 - val_loss: 2.3332 - val_accuracy: 0.1752\n",
      "Epoch 24/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2988 - accuracy: 0.1855 - val_loss: 2.3340 - val_accuracy: 0.1741\n",
      "Epoch 25/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2975 - accuracy: 0.1870 - val_loss: 2.3338 - val_accuracy: 0.1757\n",
      "Epoch 26/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2967 - accuracy: 0.1865 - val_loss: 2.3356 - val_accuracy: 0.1753\n",
      "Epoch 27/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2957 - accuracy: 0.1872 - val_loss: 2.3364 - val_accuracy: 0.1745\n",
      "Epoch 28/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2947 - accuracy: 0.1873 - val_loss: 2.3367 - val_accuracy: 0.1745\n",
      "Epoch 29/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2938 - accuracy: 0.1877 - val_loss: 2.3356 - val_accuracy: 0.1752\n",
      "Epoch 30/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2929 - accuracy: 0.1874 - val_loss: 2.3376 - val_accuracy: 0.1745\n",
      "Epoch 31/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2920 - accuracy: 0.1878 - val_loss: 2.3391 - val_accuracy: 0.1750\n",
      "Epoch 32/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2911 - accuracy: 0.1892 - val_loss: 2.3388 - val_accuracy: 0.1762\n",
      "Epoch 33/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2901 - accuracy: 0.1894 - val_loss: 2.3402 - val_accuracy: 0.1739\n",
      "Epoch 34/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2894 - accuracy: 0.1888 - val_loss: 2.3399 - val_accuracy: 0.1751\n",
      "Epoch 35/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2886 - accuracy: 0.1902 - val_loss: 2.3415 - val_accuracy: 0.1719\n",
      "Epoch 36/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2877 - accuracy: 0.1907 - val_loss: 2.3433 - val_accuracy: 0.1737\n",
      "Epoch 37/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2871 - accuracy: 0.1904 - val_loss: 2.3422 - val_accuracy: 0.1735\n",
      "Epoch 38/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2862 - accuracy: 0.1906 - val_loss: 2.3438 - val_accuracy: 0.1750\n",
      "Epoch 39/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2856 - accuracy: 0.1908 - val_loss: 2.3443 - val_accuracy: 0.1748\n",
      "Epoch 40/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2848 - accuracy: 0.1910 - val_loss: 2.3454 - val_accuracy: 0.1753\n",
      "Epoch 41/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2842 - accuracy: 0.1908 - val_loss: 2.3456 - val_accuracy: 0.1756\n",
      "Epoch 42/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2834 - accuracy: 0.1909 - val_loss: 2.3476 - val_accuracy: 0.1735\n",
      "Epoch 43/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2828 - accuracy: 0.1912 - val_loss: 2.3477 - val_accuracy: 0.1743\n",
      "Epoch 44/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2819 - accuracy: 0.1924 - val_loss: 2.3482 - val_accuracy: 0.1746\n",
      "Epoch 45/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2813 - accuracy: 0.1916 - val_loss: 2.3465 - val_accuracy: 0.1755\n",
      "Epoch 46/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2807 - accuracy: 0.1919 - val_loss: 2.3481 - val_accuracy: 0.1736\n",
      "Epoch 47/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2801 - accuracy: 0.1929 - val_loss: 2.3503 - val_accuracy: 0.1755\n",
      "Epoch 48/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2792 - accuracy: 0.1920 - val_loss: 2.3497 - val_accuracy: 0.1744\n",
      "Epoch 49/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2787 - accuracy: 0.1923 - val_loss: 2.3497 - val_accuracy: 0.1724\n",
      "Epoch 50/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2783 - accuracy: 0.1929 - val_loss: 2.3502 - val_accuracy: 0.1735\n"
     ]
    }
   ],
   "source": [
    "n_embeding=20\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(500, activation='relu', input_dim=27))\n",
    "model.add(tf.keras.layers.Dense(250, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(12, activation='softmax'))\n",
    "model.compile (optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
    "model_fitted_3 = model.fit(xTrain, yTrain, epochs = 50,batch_size=128, validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 183312 samples, validate on 61104 samples\n",
      "Epoch 1/50\n",
      "183312/183312 [==============================] - 3s 16us/sample - loss: 2.3326 - accuracy: 0.1705 - val_loss: 2.3282 - val_accuracy: 0.1750\n",
      "Epoch 2/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3260 - accuracy: 0.1745 - val_loss: 2.3248 - val_accuracy: 0.1770\n",
      "Epoch 3/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3241 - accuracy: 0.1754 - val_loss: 2.3244 - val_accuracy: 0.1750\n",
      "Epoch 4/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3229 - accuracy: 0.1761 - val_loss: 2.3236 - val_accuracy: 0.1773\n",
      "Epoch 5/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3216 - accuracy: 0.1759 - val_loss: 2.3230 - val_accuracy: 0.1782\n",
      "Epoch 6/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3203 - accuracy: 0.1770 - val_loss: 2.3242 - val_accuracy: 0.1768\n",
      "Epoch 7/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3194 - accuracy: 0.1775 - val_loss: 2.3240 - val_accuracy: 0.1773\n",
      "Epoch 8/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3180 - accuracy: 0.1781 - val_loss: 2.3237 - val_accuracy: 0.1775\n",
      "Epoch 9/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3164 - accuracy: 0.1791 - val_loss: 2.3236 - val_accuracy: 0.1767\n",
      "Epoch 10/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3155 - accuracy: 0.1791 - val_loss: 2.3254 - val_accuracy: 0.1744\n",
      "Epoch 11/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3140 - accuracy: 0.1803 - val_loss: 2.3254 - val_accuracy: 0.1738\n",
      "Epoch 12/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3129 - accuracy: 0.1818 - val_loss: 2.3248 - val_accuracy: 0.1760\n",
      "Epoch 13/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3116 - accuracy: 0.1815 - val_loss: 2.3267 - val_accuracy: 0.1759\n",
      "Epoch 14/50\n",
      "183312/183312 [==============================] - 3s 16us/sample - loss: 2.3104 - accuracy: 0.1820 - val_loss: 2.3262 - val_accuracy: 0.1761\n",
      "Epoch 15/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3091 - accuracy: 0.1816 - val_loss: 2.3284 - val_accuracy: 0.1735\n",
      "Epoch 16/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.3082 - accuracy: 0.1829 - val_loss: 2.3287 - val_accuracy: 0.1764\n",
      "Epoch 17/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3068 - accuracy: 0.1834 - val_loss: 2.3293 - val_accuracy: 0.1758\n",
      "Epoch 18/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3054 - accuracy: 0.1838 - val_loss: 2.3308 - val_accuracy: 0.1755\n",
      "Epoch 19/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3045 - accuracy: 0.1841 - val_loss: 2.3291 - val_accuracy: 0.1772\n",
      "Epoch 20/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3031 - accuracy: 0.1849 - val_loss: 2.3312 - val_accuracy: 0.1749\n",
      "Epoch 21/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3017 - accuracy: 0.1853 - val_loss: 2.3324 - val_accuracy: 0.1745\n",
      "Epoch 22/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.3008 - accuracy: 0.1848 - val_loss: 2.3339 - val_accuracy: 0.1767\n",
      "Epoch 23/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2996 - accuracy: 0.1863 - val_loss: 2.3329 - val_accuracy: 0.1753\n",
      "Epoch 24/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2986 - accuracy: 0.1865 - val_loss: 2.3368 - val_accuracy: 0.1750\n",
      "Epoch 25/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2975 - accuracy: 0.1873 - val_loss: 2.3362 - val_accuracy: 0.1744\n",
      "Epoch 26/50\n",
      "183312/183312 [==============================] - 3s 15us/sample - loss: 2.2963 - accuracy: 0.1877 - val_loss: 2.3342 - val_accuracy: 0.1738\n",
      "Epoch 27/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2954 - accuracy: 0.1867 - val_loss: 2.3368 - val_accuracy: 0.1767\n",
      "Epoch 28/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2945 - accuracy: 0.1881 - val_loss: 2.3388 - val_accuracy: 0.1711\n",
      "Epoch 29/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2934 - accuracy: 0.1883 - val_loss: 2.3375 - val_accuracy: 0.1758\n",
      "Epoch 30/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2923 - accuracy: 0.1883 - val_loss: 2.3388 - val_accuracy: 0.1738\n",
      "Epoch 31/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2917 - accuracy: 0.1884 - val_loss: 2.3396 - val_accuracy: 0.1729\n",
      "Epoch 32/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2905 - accuracy: 0.1883 - val_loss: 2.3396 - val_accuracy: 0.1760\n",
      "Epoch 33/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2899 - accuracy: 0.1888 - val_loss: 2.3445 - val_accuracy: 0.1723\n",
      "Epoch 34/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2890 - accuracy: 0.1892 - val_loss: 2.3411 - val_accuracy: 0.1742\n",
      "Epoch 35/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2880 - accuracy: 0.1895 - val_loss: 2.3415 - val_accuracy: 0.1744\n",
      "Epoch 36/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2873 - accuracy: 0.1908 - val_loss: 2.3429 - val_accuracy: 0.1728\n",
      "Epoch 37/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2861 - accuracy: 0.1896 - val_loss: 2.3446 - val_accuracy: 0.1744\n",
      "Epoch 38/50\n",
      "183312/183312 [==============================] - 3s 14us/sample - loss: 2.2855 - accuracy: 0.1906 - val_loss: 2.3485 - val_accuracy: 0.1728\n",
      "Epoch 39/50\n",
      "141056/183312 [======================>.......] - ETA: 0s - loss: 2.2834 - accuracy: 0.1910"
     ]
    }
   ],
   "source": [
    "n_embeding=20\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(500, activation='relu', input_dim=27))\n",
    "model.add(tf.keras.layers.Dense(250, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(12, activation='softmax'))\n",
    "model.compile (optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
    "model_fitted_3 = model.fit(xTrain, yTrain, epochs = 50,batch_size=128, validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding the sequence with the values in last row to max length\n",
    "to_pad = 129\n",
    "new_seq = []\n",
    "for one_seq in sequences:\n",
    "    len_one_seq = len(one_seq)\n",
    "    last_val = one_seq[-1]\n",
    "    n = to_pad - len_one_seq\n",
    "   \n",
    "    to_concat = np.repeat(one_seq[-1], n).reshape(4, n).transpose()\n",
    "    new_one_seq = np.concatenate([one_seq, to_concat])\n",
    "    new_seq.append(new_one_seq)\n",
    "final_seq = np.stack(new_seq)\n",
    "\n",
    "#truncate the sequence to length 60\n",
    "from keras.preprocessing import sequence\n",
    "seq_len = 60\n",
    "final_seq=sequence.pad_sequences(final_seq, maxlen=seq_len, padding='post', dtype='float', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embeding=20\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', input_dim=79))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(12, activation='softmax'))\n",
    "model.compile (optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
    "model_fitted_3 = model.fit(xTrain, yTrain, epochs = 20,batch_size=128, validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fitted_3 = model.fit(xTrain, yTrain, epochs = 50,batch_size=128, validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model (type_layer= 'GRU', n_layers=2, n_embeding = 100,n_epochs = 20,batch_size=256 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model (type_layer= 'GRU', n_layers=0, n_embeding = 100,n_epochs = 50,batch_size=128 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model (type_layer= 'GRU', n_layers=0, n_embeding = 300,n_epochs = 50,batch_size=128 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model (type_layer= 'LSTM', n_layers=0, n_embeding = 300,n_epochs = 50,batch_size=128 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model (type_layer= 'LSTM', n_layers=5, n_embeding = 50,n_epochs = 50,batch_size=128 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fitted_1 = create_model (type_layer= 'LSTM', n_layers=3, n_embeding = 70,n_epochs = 30,batch_size=128 )\n",
    "model_fitted_2 = create_model (type_layer= 'GRU', n_layers=3, n_embeding = 70,n_epochs = 30,batch_size=128 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embeding=20\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(500, activation='relu', input_dim=85))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(12, activation='softmax'))\n",
    "model.compile (optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
    "model_fitted_3 = model.fit(xTrain, yTrain, epochs = 20,batch_size=128, validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model__2 = Sequential()\n",
    "model__2.add(LSTM(20, input_shape=(82, 1), return_sequences=True))\n",
    "model__2.add(TimeDistributed(Dense(12, activation='sigmoid')))\n",
    "model__2.compile (optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
    "model__2 = model.fit(xTrain, yTrain, epochs = 20,batch_size=128, validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence(n_timesteps):\n",
    "    # create a sequence of random numbers in [0,1]\n",
    "    X = array([random() for _ in range(n_timesteps)])\n",
    "    # calculate cut-off value to change class values\n",
    "    limit = n_timesteps/4.0\n",
    "    # determine the class outcome for each item in cumulative sequence\n",
    "    y = array([0 if x < limit else 1 for x in cumsum(X)])\n",
    "    # reshape input and output data to be suitable for LSTMs\n",
    "    X = X.reshape(1, n_timesteps, 1)\n",
    "    y = y.reshape(1, n_timesteps, 1)\n",
    "    return X, y\n",
    " \n",
    "# define problem properties\n",
    "n_timesteps = 10\n",
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape=(n_timesteps, 1), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(12, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# train LSTM\n",
    "for epoch in range(1000):\n",
    "    # generate new random sequence\n",
    "    X,y = get_sequence(n_timesteps)\n",
    "    # fit model for one epoch on this sequence\n",
    "    model.fit(X, y, epochs=1, batch_size=1, verbose=2)\n",
    "# evaluate LSTM\n",
    "X,y = get_sequence(n_timesteps)\n",
    "yhat = model.predict_classes(X, verbose=0)\n",
    "for i in range(n_timesteps):\n",
    "    print('Expected:', y[0, i], 'Predicted', yhat[0, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
